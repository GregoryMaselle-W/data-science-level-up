{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merging external datasets...\n",
      "\n",
      "Training LGBM...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    auc, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_auc_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import joblib\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "\n",
    "def next_version_path(base_dir: str, base_name: str, ext: str = \".joblib\") -> Path:\n",
    "    base_path = Path(base_dir)\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    v = 0\n",
    "    while True:\n",
    "        candidate = base_path / f\"V{v}_{base_name}{ext}\"\n",
    "        if not candidate.exists():\n",
    "            return candidate\n",
    "        v += 1\n",
    "\n",
    "\n",
    "def months_to_expiry(date_str):\n",
    "    try:\n",
    "        mm, yy = date_str.split(\"/\")\n",
    "        exp = pd.Timestamp(year=2000 + int(yy), month=int(mm), day=1)\n",
    "        return max((exp - pd.Timestamp.now()).days // 30, 0)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "print(\"Loading data...\")\n",
    "customers   = pd.read_csv(\"customers.csv\", low_memory=False)\n",
    "terminals   = pd.read_csv(\"terminals.csv\", low_memory=False)\n",
    "merchants   = pd.read_csv(\"merchants.csv\", low_memory=False)\n",
    "transactions = pd.read_csv(\"transactions_train.csv\", low_memory=False)\n",
    "\n",
    "print(\"Merging external datasets...\")\n",
    "\n",
    "transactions[\"TX_TS\"] = pd.to_datetime(transactions[\"TX_TS\"])\n",
    "\n",
    "transactions[\"hour\"] = transactions[\"TX_TS\"].dt.hour\n",
    "transactions[\"dayofweek\"] = transactions[\"TX_TS\"].dt.dayofweek\n",
    "transactions[\"is_friday\"] = (transactions[\"dayofweek\"] == 4).astype(int)\n",
    "transactions[\"is_weekend\"] = transactions[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "transactions[\"months_to_expiry\"] = transactions[\"CARD_EXPIRY_DATE\"].apply(months_to_expiry)\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    customers.rename(columns={\"x_customer_id\":\"cust_x\",\"y_customer_id\":\"cust_y\"}),\n",
    "    on=\"CUSTOMER_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    terminals.rename(columns={\"x_terminal_id\":\"term_x\",\"y_terminal_id\":\"term_y\"}),\n",
    "    on=\"TERMINAL_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions[\"cust_term_distance\"] = np.sqrt(\n",
    "    (transactions[\"cust_x\"] - transactions[\"term_x\"])**2 +\n",
    "    (transactions[\"cust_y\"] - transactions[\"term_y\"])**2\n",
    ")\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    merchants[[\n",
    "        \"MERCHANT_ID\",\"BUSINESS_TYPE\",\"MCC_CODE\",\n",
    "        \"PAYMENT_PERCENTAGE_FACE_TO_FACE\",\"PAYMENT_PERCENTAGE_ECOM\"\n",
    "    ]],\n",
    "    on=\"MERCHANT_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions[\"TX_FRAUD\"] = transactions[\"TX_FRAUD\"].astype(int)\n",
    "\n",
    "numeric = [\n",
    "    \"TX_AMOUNT\", \"TRANSACTION_GOODS_AND_SERVICES_AMOUNT\",\n",
    "    \"TRANSACTION_CASHBACK_AMOUNT\", \"hour\", \"dayofweek\",\n",
    "    \"is_friday\", \"is_weekend\", \"months_to_expiry\",\n",
    "    \"cust_x\", \"cust_y\", \"term_x\", \"term_y\",\n",
    "    \"cust_term_distance\",\n",
    "    \"PAYMENT_PERCENTAGE_FACE_TO_FACE\",\"PAYMENT_PERCENTAGE_ECOM\"\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    \"CARD_BRAND\", \"TRANSACTION_TYPE\", \"TRANSACTION_STATUS\",\n",
    "    \"TRANSACTION_CURRENCY\", \"CARD_COUNTRY_CODE\",\n",
    "    \"IS_RECURRING_TRANSACTION\", \"CARDHOLDER_AUTH_METHOD\",\n",
    "    \"BUSINESS_TYPE\", \"MCC_CODE\"\n",
    "]\n",
    "\n",
    "X = transactions[numeric + categorical]\n",
    "y = transactions[\"TX_FRAUD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "    (\"num\", \"passthrough\", numeric),\n",
    "])\n",
    "\n",
    "models = {\n",
    "    \"LGBM\": LGBMClassifier(\n",
    "        device=\"gpu\",\n",
    "        boosting_type=\"gbdt\",\n",
    "        n_estimators=5000,          # Large number, will rely on early stopping\n",
    "        learning_rate=0.02,         # Small learning rate → better generalization\n",
    "        max_depth=10,               # Slightly deeper trees for complex patterns\n",
    "        num_leaves=128,             # More leaves to capture subtle splits\n",
    "        min_child_samples=30,       # Minimum samples per leaf → helps prevent overfitting\n",
    "        subsample=0.8,              # Row sampling → adds randomness, reduces overfit\n",
    "        colsample_bytree=0.8,       # Feature sampling per tree → adds robustness\n",
    "        reg_alpha=2.0,              # L1 regularization → reduces overfitting\n",
    "        reg_lambda=2.0,             # L2 regularization → reduces overfitting\n",
    "        scale_pos_weight=2,        # Handle imbalance (fraud is rare). Adjust based on ratio\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    pipe = Pipeline([\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"adasyn\", ADASYN(random_state=42, n_neighbors=5)),\n",
    "        (\"model\", clf)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        model__eval_set=[(X_test, y_test)],\n",
    "        model__eval_metric=\"auc\",\n",
    "        model__callbacks=[early_stopping(stopping_rounds=50), log_evaluation(50)]\n",
    "    )\n",
    "\n",
    "    y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    print(f\"{name} ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    print(f\"{name} PR AUC :\", auc(recall, precision))\n",
    "\n",
    "    y_pred = (y_prob >= 0.1).astype(int)\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    save_path = next_version_path(\"saved_models\", name)\n",
    "    joblib.dump(pipe, save_path)\n",
    "    print(f\"Saved {name} model to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638591fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LGBM from saved_models\\V8_LGBM.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet3218\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to predictions\\V8_LGBM_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = \"saved_models\"\n",
    "TEST_CSV = \"transactions_test.csv\"\n",
    "CUSTOMERS_CSV = \"customers.csv\"\n",
    "TERMINALS_CSV = \"terminals.csv\"\n",
    "MERCHANTS_CSV = \"merchants.csv\"\n",
    "PREDICTIONS_DIR = \"predictions\"\n",
    "THRESHOLD = 0.1\n",
    "\n",
    "\n",
    "def latest_models(model_dir: str):\n",
    "    p = Path(model_dir)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"{model_dir} does not exist.\")\n",
    "    models = {}\n",
    "    for f in p.glob(\"V*_*.joblib\"):\n",
    "        try:\n",
    "            v_str, name = f.stem.split(\"_\", 1)\n",
    "            v = int(v_str[1:])\n",
    "            if name not in models or v > models[name][0]:\n",
    "                models[name] = (v, f)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    if not models:\n",
    "        raise FileNotFoundError(\"No versioned models found.\")\n",
    "    return {name: path for name, (v, path) in models.items()}\n",
    "\n",
    "\n",
    "def months_to_expiry(date_str):\n",
    "    try:\n",
    "        mm, yy = date_str.split(\"/\")\n",
    "        exp = pd.Timestamp(year=2000 + int(yy), month=int(mm), day=1)\n",
    "        return max((exp - pd.Timestamp.now()).days // 30, 0)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_bool(col):\n",
    "    return col.map(lambda v:\n",
    "        \"Y\" if str(v).strip().upper() in (\"Y\",\"YES\",\"TRUE\",\"1\") else \"N\"\n",
    "    )\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV, low_memory=False)\n",
    "customers = pd.read_csv(CUSTOMERS_CSV, low_memory=False)\n",
    "terminals = pd.read_csv(TERMINALS_CSV, low_memory=False)\n",
    "merchants = pd.read_csv(MERCHANTS_CSV, low_memory=False)\n",
    "\n",
    "test_df[\"TX_TS\"] = pd.to_datetime(test_df[\"TX_TS\"])\n",
    "test_df[\"hour\"] = test_df[\"TX_TS\"].dt.hour\n",
    "test_df[\"dayofweek\"] = test_df[\"TX_TS\"].dt.dayofweek\n",
    "test_df[\"is_friday\"] = (test_df[\"dayofweek\"] == 4).astype(int)\n",
    "test_df[\"is_weekend\"] = test_df[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "test_df[\"months_to_expiry\"] = test_df[\"CARD_EXPIRY_DATE\"].apply(months_to_expiry)\n",
    "\n",
    "test_df = test_df.merge(\n",
    "    customers.rename(columns={\"x_customer_id\": \"cust_x\", \"y_customer_id\": \"cust_y\"}),\n",
    "    on=\"CUSTOMER_ID\", how=\"left\"\n",
    ")\n",
    "test_df = test_df.merge(\n",
    "    terminals.rename(columns={\"x_terminal_id\": \"term_x\", \"y_terminal_id\": \"term_y\"}),\n",
    "    on=\"TERMINAL_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "test_df[\"cust_term_distance\"] = np.sqrt(\n",
    "    (test_df[\"cust_x\"] - test_df[\"term_x\"]) ** 2 +\n",
    "    (test_df[\"cust_y\"] - test_df[\"term_y\"]) ** 2\n",
    ")\n",
    "\n",
    "test_df = test_df.merge(\n",
    "    merchants[[\n",
    "        \"MERCHANT_ID\", \"BUSINESS_TYPE\", \"MCC_CODE\",\n",
    "        \"PAYMENT_PERCENTAGE_FACE_TO_FACE\", \"PAYMENT_PERCENTAGE_ECOM\"\n",
    "    ]],\n",
    "    on=\"MERCHANT_ID\", how=\"left\"\n",
    ")\n",
    "test_df[\"IS_RECURRING_TRANSACTION\"] = normalize_bool(test_df[\"IS_RECURRING_TRANSACTION\"])\n",
    "\n",
    "Path(PREDICTIONS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "latest_model_paths = latest_models(MODEL_DIR)\n",
    "\n",
    "for model_name, path in latest_model_paths.items():\n",
    "    print(f\"Loading {model_name} from {path}\")\n",
    "    model = joblib.load(path)\n",
    "\n",
    "    feature_cols = model.named_steps[\"prep\"].feature_names_in_\n",
    "    X_test = test_df[feature_cols]\n",
    "\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    #y_pred = (y_prob >= THRESHOLD).astype(int)\n",
    "\n",
    "    version = path.stem.split(\"_\")[0]\n",
    "    out_file = Path(PREDICTIONS_DIR) / f\"{version}_{model_name}_results.csv\"\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"TX_ID\": test_df[\"TX_ID\"],\n",
    "        \"TX_FRAUD\": y_prob\n",
    "    }).to_csv(out_file, index=False)\n",
    "\n",
    "    print(f\"Saved predictions to {out_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
