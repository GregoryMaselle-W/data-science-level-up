{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b73e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyopencl.Platform 'Intel(R) OpenCL Graphics' at 0x29570ae73c0>,\n",
       " <pyopencl.Platform 'NVIDIA CUDA' at 0x2959abe9710>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyopencl as cl\n",
    "cl.get_platforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4bc0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Transforming features...\n",
      "Generating oversampled training data with ADASYN using all cpu cores...\n",
      "\n",
      "Training LGBM...\n",
      "[LightGBM] [Info] Number of positive: 835947, number of negative: 831101\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 86056\n",
      "[LightGBM] [Info] Number of data points in the train set: 1667048, number of used features: 360\n",
      "[LightGBM] [Info] Using requested OpenCL platform 1 device 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA RTX A500 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (25.44 MB) transferred to GPU in 0.064697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501453 -> initscore=0.005814\n",
      "[LightGBM] [Info] Start training from score 0.005814\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's auc: 0.568756\tvalid_0's binary_logloss: 0.315475\n",
      "[100]\tvalid_0's auc: 0.579186\tvalid_0's binary_logloss: 0.200674\n",
      "[150]\tvalid_0's auc: 0.596238\tvalid_0's binary_logloss: 0.158127\n",
      "[200]\tvalid_0's auc: 0.627199\tvalid_0's binary_logloss: 0.139631\n",
      "[250]\tvalid_0's auc: 0.664437\tvalid_0's binary_logloss: 0.129753\n",
      "[300]\tvalid_0's auc: 0.69692\tvalid_0's binary_logloss: 0.123344\n",
      "[350]\tvalid_0's auc: 0.715868\tvalid_0's binary_logloss: 0.119048\n",
      "[400]\tvalid_0's auc: 0.73732\tvalid_0's binary_logloss: 0.11451\n",
      "[450]\tvalid_0's auc: 0.748192\tvalid_0's binary_logloss: 0.109368\n",
      "[500]\tvalid_0's auc: 0.751801\tvalid_0's binary_logloss: 0.106361\n",
      "[550]\tvalid_0's auc: 0.754289\tvalid_0's binary_logloss: 0.104015\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's auc: 0.757608\tvalid_0's binary_logloss: 0.101536\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[650]\tvalid_0's auc: 0.759499\tvalid_0's binary_logloss: 0.100037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[700]\tvalid_0's auc: 0.759871\tvalid_0's binary_logloss: 0.0990297\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[750]\tvalid_0's auc: 0.760784\tvalid_0's binary_logloss: 0.0981257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\tvalid_0's auc: 0.762933\tvalid_0's binary_logloss: 0.0973434\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[850]\tvalid_0's auc: 0.7662\tvalid_0's binary_logloss: 0.0962113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[900]\tvalid_0's auc: 0.768267\tvalid_0's binary_logloss: 0.0956082\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[950]\tvalid_0's auc: 0.772369\tvalid_0's binary_logloss: 0.0946419\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\tvalid_0's auc: 0.77463\tvalid_0's binary_logloss: 0.0938671\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1050]\tvalid_0's auc: 0.77868\tvalid_0's binary_logloss: 0.0930994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1100]\tvalid_0's auc: 0.780472\tvalid_0's binary_logloss: 0.0927345\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1150]\tvalid_0's auc: 0.781914\tvalid_0's binary_logloss: 0.0922917\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1200]\tvalid_0's auc: 0.78427\tvalid_0's binary_logloss: 0.0917966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1250]\tvalid_0's auc: 0.787295\tvalid_0's binary_logloss: 0.0912064\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1300]\tvalid_0's auc: 0.789765\tvalid_0's binary_logloss: 0.0906726\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1350]\tvalid_0's auc: 0.791817\tvalid_0's binary_logloss: 0.0902795\n",
      "[1400]\tvalid_0's auc: 0.793126\tvalid_0's binary_logloss: 0.0899456\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1450]\tvalid_0's auc: 0.79399\tvalid_0's binary_logloss: 0.0897165\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1500]\tvalid_0's auc: 0.796213\tvalid_0's binary_logloss: 0.089351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1550]\tvalid_0's auc: 0.79958\tvalid_0's binary_logloss: 0.0888143\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1600]\tvalid_0's auc: 0.801277\tvalid_0's binary_logloss: 0.0884871\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1650]\tvalid_0's auc: 0.803446\tvalid_0's binary_logloss: 0.0880984\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1700]\tvalid_0's auc: 0.805008\tvalid_0's binary_logloss: 0.0878657\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1750]\tvalid_0's auc: 0.805794\tvalid_0's binary_logloss: 0.0876423\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1800]\tvalid_0's auc: 0.808152\tvalid_0's binary_logloss: 0.0873217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1850]\tvalid_0's auc: 0.808947\tvalid_0's binary_logloss: 0.0871495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1900]\tvalid_0's auc: 0.810789\tvalid_0's binary_logloss: 0.0868489\n",
      "[1950]\tvalid_0's auc: 0.811347\tvalid_0's binary_logloss: 0.0866997\n",
      "[2000]\tvalid_0's auc: 0.812729\tvalid_0's binary_logloss: 0.0865132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2050]\tvalid_0's auc: 0.814413\tvalid_0's binary_logloss: 0.0863075\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2100]\tvalid_0's auc: 0.817156\tvalid_0's binary_logloss: 0.0859495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2150]\tvalid_0's auc: 0.819301\tvalid_0's binary_logloss: 0.0856328\n",
      "[2200]\tvalid_0's auc: 0.821767\tvalid_0's binary_logloss: 0.0853387\n",
      "[2250]\tvalid_0's auc: 0.823221\tvalid_0's binary_logloss: 0.0851253\n",
      "[2300]\tvalid_0's auc: 0.825006\tvalid_0's binary_logloss: 0.0848263\n",
      "[2350]\tvalid_0's auc: 0.827752\tvalid_0's binary_logloss: 0.0844584\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2400]\tvalid_0's auc: 0.829422\tvalid_0's binary_logloss: 0.0842001\n",
      "[2450]\tvalid_0's auc: 0.830601\tvalid_0's binary_logloss: 0.0840269\n",
      "[2500]\tvalid_0's auc: 0.83298\tvalid_0's binary_logloss: 0.0837333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2550]\tvalid_0's auc: 0.834577\tvalid_0's binary_logloss: 0.0835069\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2600]\tvalid_0's auc: 0.835449\tvalid_0's binary_logloss: 0.0833013\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2650]\tvalid_0's auc: 0.8368\tvalid_0's binary_logloss: 0.0830685\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2700]\tvalid_0's auc: 0.838168\tvalid_0's binary_logloss: 0.0828652\n",
      "[2750]\tvalid_0's auc: 0.839239\tvalid_0's binary_logloss: 0.0826442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2800]\tvalid_0's auc: 0.839525\tvalid_0's binary_logloss: 0.0825325\n",
      "[2850]\tvalid_0's auc: 0.840871\tvalid_0's binary_logloss: 0.0823253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2900]\tvalid_0's auc: 0.842074\tvalid_0's binary_logloss: 0.0820722\n",
      "[2950]\tvalid_0's auc: 0.84314\tvalid_0's binary_logloss: 0.0818999\n",
      "[3000]\tvalid_0's auc: 0.844231\tvalid_0's binary_logloss: 0.0817217\n",
      "[3050]\tvalid_0's auc: 0.845439\tvalid_0's binary_logloss: 0.0815318\n",
      "[3100]\tvalid_0's auc: 0.846041\tvalid_0's binary_logloss: 0.0813375\n",
      "[3150]\tvalid_0's auc: 0.846574\tvalid_0's binary_logloss: 0.0811919\n",
      "[3200]\tvalid_0's auc: 0.847654\tvalid_0's binary_logloss: 0.0810126\n",
      "[3250]\tvalid_0's auc: 0.848549\tvalid_0's binary_logloss: 0.0808425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3300]\tvalid_0's auc: 0.848972\tvalid_0's binary_logloss: 0.080702\n",
      "[3350]\tvalid_0's auc: 0.8495\tvalid_0's binary_logloss: 0.0805849\n",
      "[3400]\tvalid_0's auc: 0.850589\tvalid_0's binary_logloss: 0.0804073\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3450]\tvalid_0's auc: 0.850645\tvalid_0's binary_logloss: 0.0803406\n",
      "[3500]\tvalid_0's auc: 0.850766\tvalid_0's binary_logloss: 0.0802443\n",
      "[3550]\tvalid_0's auc: 0.851429\tvalid_0's binary_logloss: 0.0800882\n",
      "[3600]\tvalid_0's auc: 0.852287\tvalid_0's binary_logloss: 0.0799273\n",
      "[3650]\tvalid_0's auc: 0.852443\tvalid_0's binary_logloss: 0.0798325\n",
      "[3700]\tvalid_0's auc: 0.852883\tvalid_0's binary_logloss: 0.0797061\n",
      "[3750]\tvalid_0's auc: 0.853421\tvalid_0's binary_logloss: 0.0795763\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3800]\tvalid_0's auc: 0.853868\tvalid_0's binary_logloss: 0.0794595\n",
      "[3850]\tvalid_0's auc: 0.85429\tvalid_0's binary_logloss: 0.0793297\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3900]\tvalid_0's auc: 0.854816\tvalid_0's binary_logloss: 0.0792003\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3950]\tvalid_0's auc: 0.855098\tvalid_0's binary_logloss: 0.0791017\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4000]\tvalid_0's auc: 0.855273\tvalid_0's binary_logloss: 0.0790097\n",
      "[4050]\tvalid_0's auc: 0.855634\tvalid_0's binary_logloss: 0.0788844\n",
      "[4100]\tvalid_0's auc: 0.855829\tvalid_0's binary_logloss: 0.0787885\n",
      "[4150]\tvalid_0's auc: 0.855948\tvalid_0's binary_logloss: 0.0787127\n",
      "[4200]\tvalid_0's auc: 0.85664\tvalid_0's binary_logloss: 0.0785613\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4250]\tvalid_0's auc: 0.856782\tvalid_0's binary_logloss: 0.0784845\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4300]\tvalid_0's auc: 0.856824\tvalid_0's binary_logloss: 0.0784143\n",
      "Early stopping, best iteration is:\n",
      "[4284]\tvalid_0's auc: 0.856921\tvalid_0's binary_logloss: 0.0784339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet3218\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM ROC AUC: 0.8569209911367108\n",
      "LGBM PR AUC : 0.5143267851402666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.985     0.986    207775\n",
      "           1      0.462     0.487     0.475      5513\n",
      "\n",
      "    accuracy                          0.972    213288\n",
      "   macro avg      0.724     0.736     0.730    213288\n",
      "weighted avg      0.973     0.972     0.972    213288\n",
      "\n",
      "Confusion matrix:\n",
      " [[204651   3124]\n",
      " [  2826   2687]]\n",
      "Saved LGBM model + preprocessor to saved_models\\V0_LGBM.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    auc, classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_auc_score\n",
    ")\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import joblib\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Utilities\n",
    "# -------------------------------------------------------------------\n",
    "def next_version_path(base_dir: str, base_name: str, ext: str = \".joblib\") -> Path:\n",
    "    base_path = Path(base_dir)\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    v = 0\n",
    "    while True:\n",
    "        candidate = base_path / f\"V{v}_{base_name}{ext}\"\n",
    "        if not candidate.exists():\n",
    "            return candidate\n",
    "        v += 1\n",
    "\n",
    "def months_to_expiry(date_str):\n",
    "    try:\n",
    "        mm, yy = date_str.split(\"/\")\n",
    "        exp = pd.Timestamp(year=2000 + int(yy), month=int(mm), day=1)\n",
    "        return max((exp - pd.Timestamp.now()).days // 30, 0)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load & merge data\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Loading data...\")\n",
    "customers   = pd.read_csv(\"customers.csv\", low_memory=False)\n",
    "terminals   = pd.read_csv(\"terminals.csv\", low_memory=False)\n",
    "merchants   = pd.read_csv(\"merchants.csv\", low_memory=False)\n",
    "transactions = pd.read_csv(\"transactions_train.csv\", low_memory=False)\n",
    "\n",
    "transactions[\"TX_TS\"] = pd.to_datetime(transactions[\"TX_TS\"])\n",
    "transactions[\"hour\"] = transactions[\"TX_TS\"].dt.hour\n",
    "transactions[\"dayofweek\"] = transactions[\"TX_TS\"].dt.dayofweek\n",
    "transactions[\"is_friday\"] = (transactions[\"dayofweek\"] == 4).astype(int)\n",
    "transactions[\"is_weekend\"] = transactions[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "transactions[\"months_to_expiry\"] = transactions[\"CARD_EXPIRY_DATE\"].apply(months_to_expiry)\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    customers.rename(columns={\"x_customer_id\":\"cust_x\",\"y_customer_id\":\"cust_y\"}),\n",
    "    on=\"CUSTOMER_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    terminals.rename(columns={\"x_terminal_id\":\"term_x\",\"y_terminal_id\":\"term_y\"}),\n",
    "    on=\"TERMINAL_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions[\"cust_term_distance\"] = np.sqrt(\n",
    "    (transactions[\"cust_x\"] - transactions[\"term_x\"])**2 +\n",
    "    (transactions[\"cust_y\"] - transactions[\"term_y\"])**2\n",
    ")\n",
    "\n",
    "transactions = transactions.merge(\n",
    "    merchants[[\n",
    "        \"MERCHANT_ID\",\"BUSINESS_TYPE\",\"MCC_CODE\",\n",
    "        \"PAYMENT_PERCENTAGE_FACE_TO_FACE\",\"PAYMENT_PERCENTAGE_ECOM\"\n",
    "    ]],\n",
    "    on=\"MERCHANT_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "transactions[\"TX_FRAUD\"] = transactions[\"TX_FRAUD\"].astype(int)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Features\n",
    "# -------------------------------------------------------------------\n",
    "numeric = [\n",
    "    \"TX_AMOUNT\", \"TRANSACTION_GOODS_AND_SERVICES_AMOUNT\",\n",
    "    \"TRANSACTION_CASHBACK_AMOUNT\", \"hour\", \"dayofweek\",\n",
    "    \"is_friday\", \"is_weekend\", \"months_to_expiry\",\n",
    "    \"cust_x\", \"cust_y\", \"term_x\", \"term_y\",\n",
    "    \"cust_term_distance\",\n",
    "    \"PAYMENT_PERCENTAGE_FACE_TO_FACE\",\"PAYMENT_PERCENTAGE_ECOM\"\n",
    "]\n",
    "\n",
    "categorical = [\n",
    "    \"CARD_BRAND\", \"TRANSACTION_TYPE\", \"TRANSACTION_STATUS\",\n",
    "    \"TRANSACTION_CURRENCY\", \"CARD_COUNTRY_CODE\",\n",
    "    \"IS_RECURRING_TRANSACTION\", \"CARDHOLDER_AUTH_METHOD\",\n",
    "    \"BUSINESS_TYPE\", \"MCC_CODE\"\n",
    "]\n",
    "\n",
    "X = transactions[numeric + categorical]\n",
    "y = transactions[\"TX_FRAUD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline (no oversampling here)\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical),\n",
    "    (\"num\", \"passthrough\", numeric),\n",
    "])\n",
    "\n",
    "# Fit preprocessor and transform datasets\n",
    "print(\"Transforming features...\")\n",
    "X_train_t = preprocessor.fit_transform(X_train)\n",
    "X_test_t  = preprocessor.transform(X_test)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Oversample training set only\n",
    "# -------------------------------------------------------------------\n",
    "print(\"Generating oversampled training data with ADASYN using all cpu cores...\")\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=5)\n",
    "X_train_os, y_train_os = adasyn.fit_resample(X_train_t, y_train)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Models\n",
    "# -------------------------------------------------------------------\n",
    "models = {\n",
    "    \"LGBM\": LGBMClassifier(\n",
    "        device=\"gpu\",\n",
    "        gpu_platform_id=1,   # NVIDIA\n",
    "        gpu_device_id=0,     # first device\n",
    "        boosting_type=\"gbdt\",\n",
    "        n_estimators=5000,   # large → early stopping\n",
    "        learning_rate=0.02,\n",
    "        max_depth=10,\n",
    "        num_leaves=128,\n",
    "        min_child_samples=30,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=2.0,\n",
    "        reg_lambda=2.0,\n",
    "        scale_pos_weight=2,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Training loop\n",
    "# -------------------------------------------------------------------\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    clf.fit(\n",
    "        X_train_os, y_train_os,\n",
    "        eval_set=[(X_test_t, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "        callbacks=[early_stopping(50), log_evaluation(50)]\n",
    "    )\n",
    "\n",
    "    # Predict on test set\n",
    "    y_prob = clf.predict_proba(X_test_t)[:, 1]\n",
    "    print(f\"{name} ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    print(f\"{name} PR AUC :\", auc(recall, precision))\n",
    "\n",
    "    y_pred = (y_prob >= 0.1).astype(int)\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    save_path = next_version_path(\"saved_models\", name)\n",
    "    joblib.dump((clf, preprocessor), save_path)\n",
    "    print(f\"Saved {name} model + preprocessor to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638591fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LGBM from saved_models\\V0_LGBM.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbdnet3218\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to predictions\\V0_LGBM_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = \"saved_models\"\n",
    "TEST_CSV = \"transactions_test.csv\"\n",
    "CUSTOMERS_CSV = \"customers.csv\"\n",
    "TERMINALS_CSV = \"terminals.csv\"\n",
    "MERCHANTS_CSV = \"merchants.csv\"\n",
    "PREDICTIONS_DIR = \"predictions\"\n",
    "THRESHOLD = 0.1\n",
    "\n",
    "def latest_models(model_dir: str):\n",
    "    p = Path(model_dir)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"{model_dir} does not exist.\")\n",
    "    models = {}\n",
    "    for f in p.glob(\"V*_*.joblib\"):\n",
    "        try:\n",
    "            v_str, name = f.stem.split(\"_\", 1)\n",
    "            v = int(v_str[1:])\n",
    "            if name not in models or v > models[name][0]:\n",
    "                models[name] = (v, f)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    if not models:\n",
    "        raise FileNotFoundError(\"No versioned models found.\")\n",
    "    return {name: path for name, (v, path) in models.items()}\n",
    "\n",
    "def months_to_expiry(date_str):\n",
    "    try:\n",
    "        mm, yy = date_str.split(\"/\")\n",
    "        exp = pd.Timestamp(year=2000 + int(yy), month=int(mm), day=1)\n",
    "        return max((exp - pd.Timestamp.now()).days // 30, 0)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_bool(col):\n",
    "    return col.map(lambda v:\n",
    "        \"Y\" if str(v).strip().upper() in (\"Y\",\"YES\",\"TRUE\",\"1\") else \"N\"\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# Load data\n",
    "# ----------------------------\n",
    "test_df = pd.read_csv(TEST_CSV, low_memory=False)\n",
    "customers = pd.read_csv(CUSTOMERS_CSV, low_memory=False)\n",
    "terminals = pd.read_csv(TERMINALS_CSV, low_memory=False)\n",
    "merchants = pd.read_csv(MERCHANTS_CSV, low_memory=False)\n",
    "\n",
    "# ----------------------------\n",
    "# Feature engineering\n",
    "# ----------------------------\n",
    "test_df[\"TX_TS\"] = pd.to_datetime(test_df[\"TX_TS\"])\n",
    "test_df[\"hour\"] = test_df[\"TX_TS\"].dt.hour\n",
    "test_df[\"dayofweek\"] = test_df[\"TX_TS\"].dt.dayofweek\n",
    "test_df[\"is_friday\"] = (test_df[\"dayofweek\"] == 4).astype(int)\n",
    "test_df[\"is_weekend\"] = test_df[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "test_df[\"months_to_expiry\"] = test_df[\"CARD_EXPIRY_DATE\"].apply(months_to_expiry)\n",
    "\n",
    "test_df = test_df.merge(\n",
    "    customers.rename(columns={\"x_customer_id\": \"cust_x\", \"y_customer_id\": \"cust_y\"}),\n",
    "    on=\"CUSTOMER_ID\", how=\"left\"\n",
    ")\n",
    "test_df = test_df.merge(\n",
    "    terminals.rename(columns={\"x_terminal_id\": \"term_x\", \"y_terminal_id\": \"term_y\"}),\n",
    "    on=\"TERMINAL_ID\", how=\"left\"\n",
    ")\n",
    "\n",
    "test_df[\"cust_term_distance\"] = np.sqrt(\n",
    "    (test_df[\"cust_x\"] - test_df[\"term_x\"]) ** 2 +\n",
    "    (test_df[\"cust_y\"] - test_df[\"term_y\"]) ** 2\n",
    ")\n",
    "\n",
    "test_df = test_df.merge(\n",
    "    merchants[[\n",
    "        \"MERCHANT_ID\", \"BUSINESS_TYPE\", \"MCC_CODE\",\n",
    "        \"PAYMENT_PERCENTAGE_FACE_TO_FACE\", \"PAYMENT_PERCENTAGE_ECOM\"\n",
    "    ]],\n",
    "    on=\"MERCHANT_ID\", how=\"left\"\n",
    ")\n",
    "test_df[\"IS_RECURRING_TRANSACTION\"] = normalize_bool(test_df[\"IS_RECURRING_TRANSACTION\"])\n",
    "\n",
    "# ----------------------------\n",
    "# Load models\n",
    "# ----------------------------\n",
    "Path(PREDICTIONS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "latest_model_paths = latest_models(MODEL_DIR)\n",
    "\n",
    "for model_name, path in latest_model_paths.items():\n",
    "    print(f\"Loading {model_name} from {path}\")\n",
    "    \n",
    "    # Unpack saved tuple (trained_model, preprocessor)\n",
    "    trained_model, preprocessor = joblib.load(path)\n",
    "\n",
    "    # Transform test data using preprocessor\n",
    "    X_test = preprocessor.transform(test_df)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_prob = trained_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= THRESHOLD).astype(int)\n",
    "\n",
    "    # Save predictions\n",
    "    version = path.stem.split(\"_\")[0]\n",
    "    out_file = Path(PREDICTIONS_DIR) / f\"{version}_{model_name}_results.csv\"\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"TX_ID\": test_df[\"TX_ID\"],\n",
    "        \"TX_FRAUD\": y_prob\n",
    "    }).to_csv(out_file, index=False)\n",
    "\n",
    "    print(f\"Saved predictions to {out_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
